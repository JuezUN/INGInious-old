#!/usr/bin/env python3
# -*- coding: utf-8 -*-
#
# This file is part of INGInious. See the LICENSE and the COPYRIGHTS files for
# more information about the licensing of this file.
#

""" Starts an agent """

import argparse
import importlib
import logging
import os
import multiprocessing

import sys
from zmq.asyncio import ZMQEventLoop, Context
import asyncio

from inginious.common.filesystems.local import LocalFSProvider
from inginious.agent.docker_agent import DockerAgent


def check_range(value):
    value = value.split("-")
    if len(value) != 2:
        raise argparse.ArgumentTypeError("Port range should be in the form 'begin-end', for example 1000-2000")

    try:
        begin = int(value[0])
        end = int(value[1])
    except:
        raise argparse.ArgumentTypeError("Port range should be in the form 'begin-end', for example 1000-2000")

    if begin > end:
        (begin, end) = end, begin

    return range(begin, end+1)


def check_negative(value):
    try:
        ivalue = int(value)
    except:
        raise argparse.ArgumentTypeError("%s is an invalid positive int value" % value)

    if ivalue <= 0:
        raise argparse.ArgumentTypeError("%s is an invalid positive int value" % value)
    return ivalue

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("backend", help="Address to the backend, in the form protocol://host:port. For example, tcp://127.0.0.1:2000", type=str)
    parser.add_argument("--friendly-name", help="Friendly name to help identify agent.", default="", type=str)
    parser.add_argument("--debug-host", help="Host used for job remote debugging. Should be an IP or an hostname. If not filled in, "
                                             "it will be automatically guessed", default=None, type=str)
    parser.add_argument("--debug-ports", help="Range of port for job remote debugging. By default it is 64120-64130", type=check_range, default="64120-64130")
    parser.add_argument("--tmpdir", help="Path to a directory where the agent can store information, such as caches. Defaults to ./agent_data",
                        default="./agent_data")
    parser.add_argument("--concurrency", help="Maximal number of jobs that can run concurrently on this agent. By default, it is the two times the "
                                              "number of cores available.", default=multiprocessing.cpu_count(), type=check_negative)
    parser.add_argument("-v", "--verbose", help="increase output verbosity",
                        action="store_true")

    fs_group = parser.add_mutually_exclusive_group()
    fs_group.add_argument("--tasks", help="Path to the task directory. "
                                          "By default, it is ./tasks. You must ensure that this directory is synchronized at any time"
                                          "with the backend and the client. Either this option or --fs must be indicated, but not both.",
                          type=str, default="./tasks")
    fs_group.add_argument("--fs", help="(advanced users only) A full Python include path to a FileSystemProvider class, to be used a the filesystem "
                                       "provider. Using a FSProvider will add new args to be filled. Either --fs or --tasks must be filled, "
                                       "but not both.",
                          type=str)
    parser.add_argument("--fs-help", help="Display help to fill arguments for --fs. Only checked if --fs is filled.", action="store_true")

    # Partial parsing of the args, to get the value of --fs
    args = parser.parse_known_args()[0]

    # check fs
    if args.fs is not None:
        fs_include = args.fs.split(".")

        try:
            module = importlib.import_module(".".join(fs_include[:-1]))
            fs_class = getattr(module, fs_include[-1])
            fs_args_needed = fs_class.get_needed_args()
        except:
            print("Unable to load class " + args.fs, file=sys.stderr)
            raise

        fs_args_group = parser.add_argument_group("FSProvider arguments")
        for arg_name, (arg_type, arg_required, arg_desc) in fs_args_needed.items():
            fs_args_group.add_argument("--fs-" + arg_name, type=arg_type, help=arg_desc, required=arg_required)
        if args.fs_help:
            parser.parse_args(["--help"])
        args = parser.parse_args()

        returned_args = {}
        for arg_name in fs_args_needed:
            val = getattr(args, ("fs-" + arg_name).replace("-", "_"))
            if val is not None:
                returned_args[arg_name] = val

        try:
            fsprovider = fs_class.init_from_args(**returned_args)
        except:
            print("Unable to load class " + args.fs, file=sys.stderr)
            raise
    else:
        # Verify that everything can finally be parsed
        args = parser.parse_args()
        fsprovider = LocalFSProvider(args.tasks)

    if not os.path.exists(args.tmpdir):
        os.makedirs(args.tmpdir)

    # create logger
    logger = logging.getLogger("inginious")
    logger.setLevel(logging.INFO if not args.verbose else logging.DEBUG)
    ch = logging.StreamHandler()
    ch.setLevel(logging.INFO if not args.verbose else logging.DEBUG)
    formatter = logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")
    ch.setFormatter(formatter)
    logger.addHandler(ch)

    # start asyncio and zmq
    loop = ZMQEventLoop()
    asyncio.set_event_loop(loop)
    context = Context()

    # Create agent
    agent = DockerAgent(context, args.backend, args.friendly_name, args.concurrency, fsprovider, ssh_host=args.debug_host,
                        ssh_ports=args.debug_ports, tmp_dir=args.tmpdir)

    # Run!
    try:
        loop.run_until_complete(agent.run_dealer())
    except:
        pass
    finally:
        logger.info("Closing loop")
        loop.close()
        logger.info("Waiting for ZMQ to send remaining messages to backend (can take 1 sec)")
        context.destroy(1000)  # give zeromq 1 sec to send remaining messages
        logger.info("Done")
